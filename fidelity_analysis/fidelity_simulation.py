import os
from typing import Union

import numpy as np
import skrf as rf
from joblib import Parallel, delayed
from matplotlib import pyplot as plt
from matplotlib.colors import ListedColormap
from scipy.signal import butter, filtfilt
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from skrf import Network
from tqdm import tqdm
from fidelity_analysis.pulse import Pulse, TransitedPulse, ReflectedPulse, ReadoutPulse

"""
Fidelity simulation based on the paper

Wong, Hiu Yung, Prabjot Dhillon, Kristin M. Beck, and Yaniv J. Rosen. 2023. 
“A Simulation Methodology for Superconducting Qubit Readout Fidelity.” 
Solid-State Electronics 201 (March):108582. https://doi.org/10.1016/j.sse.2022.108582.
"""


class FidelitySimulation:
    def __init__(
            self,
            readout_pulse: ReadoutPulse,
            s_parameters_file_state_0: Union[str, Network],
            s_parameters_file_state_1: Union[str, Network],
            IQ_projection_frequency: float,
            # readout_type can be "transition" or "reflection"
            readout_type: str = "transition",
            num_iterations: int = 50,
            noise_parameters: dict = None,
            readout_dt: float = None,
            plot_pulses: bool = False,
            plot_result: bool = False,
            disable_progress_bar: bool = False,
            path_for_images: str = None
    ):

        self.s_parameters_file_state_0 = s_parameters_file_state_0
        self.s_parameters_file_state_1 = s_parameters_file_state_1
        self.readout_pulse = readout_pulse
        self.readout_type = readout_type
        self.IQ_projection_frequency = IQ_projection_frequency
        self.num_iterations = num_iterations
        self.readout_dt = readout_dt
        self.plot_pulses = plot_pulses
        self.plot_result = plot_result
        self.disable_progress_bar = disable_progress_bar
        self.path_for_images = path_for_images

        # Noise parameters based on the paper
        self.amplifier_gains_db = {
            "TWPA": 20.0,
            "HEMT": 40.0,
            "RoomTemp": 40.0,
        }

        # Noise parameters based on the paper
        if noise_parameters is None:
            noise_parameters = {
                # This noise is generated by the first amplifier (TWPA)
                "quantum_noise": {
                    "type": "quantum",
                    "T": 0.5,  # K
                    "stage": "TWPA",  # First stage
                    "bandwidth": 1 / self.readout_pulse.pulse_duration,
                },
                # This noise is from the HEMT, which is after the TWPA
                "thermal_noise_hemt": {
                    "type": "thermal",
                    "T": 1.5,  # K
                    "bandwidth": 6e9,  # Hz
                    "resistance": 50.0,
                    "stage": "HEMT"  # Second stage
                },
                # This noise is from the room temp amp, after TWPA and HEMT
                "thermal_noise_room_temp": {
                    "type": "thermal",
                    "T": 54,  # K (This value from the paper is unusually low for a 300K amp, but we follow it)
                    "bandwidth": 6e9,  # Hz
                    "resistance": 50.0,
                    "stage": "RoomTemp"  # Third stage
                }
            }
        self.noise_parameters = noise_parameters

    def run(self) -> float:
        if type(self.s_parameters_file_state_0) is str:
            ntw_state_0 = rf.Network(self.s_parameters_file_state_0)
        else:
            ntw_state_0 = self.s_parameters_file_state_0
        if type(self.s_parameters_file_state_1) is str:
            ntw_state_1 = rf.Network(self.s_parameters_file_state_1)
        else:
            ntw_state_1 = self.s_parameters_file_state_1

        if self.readout_type == "transition":
            signal_state_0 = TransitedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_0,
                                            name=r"Transited Pulser $|0\rangle$")
            signal_state_1 = TransitedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_1,
                                            name=r"Transited Pulse $|1\rangle$")
        elif self.readout_type == "reflection":
            signal_state_0 = ReflectedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_0,
                                            name=r"Reflected Pulse $|0\rangle$")
            signal_state_1 = ReflectedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_1,
                                            name=r"Reflected Pulse $|1\rangle$")
        else:
            raise NotImplementedError

        I_state_0, Q_state_0 = self._IQ_projection_demodulation(signal_from_system=signal_state_0)
        I_state_1, Q_state_1 = self._IQ_projection_demodulation(signal_from_system=signal_state_1)

        fidelity = self._calculate_fidelity(I_state_0, Q_state_0, I_state_1, Q_state_1)

        return fidelity

    # Noise independent of signal power, handling amplifier cascade and different noise types
    def _create_noise(self, signal_from_system: Pulse) -> np.ndarray:
        k = 1.3806e-23  # Boltzmann constant (J/K)
        signal_length = len(signal_from_system.t_signal)
        total_noise_voltage = np.zeros(signal_length)

        dt = signal_from_system.t_signal_times[1] - signal_from_system.t_signal_times[0]
        sample_rate = 1 / dt

        stage_order = ["TWPA", "HEMT", "RoomTemp"]
        preceding_voltage_gain = 1.0

        for stage_name in stage_order:
            noise_params = None
            for name, params in self.noise_parameters.items():
                if params.get("stage") == stage_name:
                    noise_params = params
                    break

            if noise_params is None:
                continue

            R = noise_params.get("resistance", 50.0)
            bandwidth = noise_params.get("bandwidth")

            T = noise_params["T"]

            voltage_spectral_density = np.sqrt(4 * k * T * R)

            nyquist_freq = sample_rate / 2
            sigma_full_bw = voltage_spectral_density * np.sqrt(nyquist_freq)
            unscaled_noise = np.random.normal(0, sigma_full_bw, size=signal_length)

            low_cutoff = self.readout_pulse.carrier_frequency - (bandwidth / 2)
            high_cutoff = self.readout_pulse.carrier_frequency + (bandwidth / 2)

            if high_cutoff >= nyquist_freq:
                raise ValueError("The filter's high cutoff frequency is at or above the Nyquist frequency.")

            a, b = butter(1, [low_cutoff, high_cutoff], btype='bandpass', fs=sample_rate)

            unscaled_noise = filtfilt(a, b, unscaled_noise)

            referred_noise = unscaled_noise / preceding_voltage_gain
            total_noise_voltage += referred_noise

            stage_power_gain_db = self.amplifier_gains_db.get(stage_name, 0)
            stage_power_gain_linear = 10 ** (stage_power_gain_db / 10.0)
            stage_voltage_gain = np.sqrt(stage_power_gain_linear)
            preceding_voltage_gain *= stage_voltage_gain

        return total_noise_voltage

    def _IQ_projection_demodulation(self, signal_from_system: Pulse):
        """
        Supports both heterodyne (f_if != 0) and homodyne (f_if == 0) cases.
        """
        if self.plot_pulses:
            signal_from_system.plot_pulse()

        dt = signal_from_system.t_signal_times[1] - signal_from_system.t_signal_times[0]
        sample_rate = 1 / dt
        t = signal_from_system.t_signal_times

        f_ro = self.readout_pulse.carrier_frequency  # Readout frequency
        f_lo = self.IQ_projection_frequency  # Local Oscillator frequency
        f_if = f_ro - f_lo  # Intermediate Frequency (IF)

        if f_if == 0:  # Homodyne detection
            # We remove the 2*f_ro component.
            cutoff_homodyne = 1e9
            b_lp, a_lp = butter(1, cutoff_homodyne, btype="lowpass", fs=sample_rate)
        else:  # Heterodyne detection
            # Isolating the IF signal. Must pass f_if, reject f_ro + f_lo.
            # A cutoff of 2*f_if has to be enough
            cutoff_analog = np.abs(f_if * 2)
            b_analog, a_analog = butter(1, cutoff_analog, btype="lowpass", fs=sample_rate)

        if self.readout_dt:
            sampling_factor = int(self.readout_dt / dt)
            if sampling_factor < 1: sampling_factor = 1
        else:
            sampling_factor = 1

        def _process_single_projection():
            noise = self._create_noise(signal_from_system=signal_from_system)
            s = (signal_from_system.t_signal + noise).real

            if f_if == 0:  # Homodyne detection
                lo_I = np.cos(2 * np.pi * f_ro * t)
                lo_Q = -np.sin(2 * np.pi * f_ro * t)

                mixed_I = s * lo_I
                mixed_Q = s * lo_Q

                # Low-pass filter to get the baseband signal
                I_baseband = filtfilt(b_lp, a_lp, mixed_I)
                Q_baseband = filtfilt(b_lp, a_lp, mixed_Q)
            else:  # Heterodyne detection
                lo_I = np.cos(2 * np.pi * f_lo * t)
                lo_Q = -np.sin(2 * np.pi * f_lo * t)

                mixed_analog_I = s * lo_I
                mixed_analog_Q = s * lo_Q

                # Low-pass filter to isolate the IF signal
                I_if = filtfilt(b_analog, a_analog, mixed_analog_I)
                Q_if = filtfilt(b_analog, a_analog, mixed_analog_Q)

                # From IF to DC
                # Create a digital complex oscillator at f_if to mix down to 0 Hz (DC).
                # We need to create z_if = I_if + j*Q_if and multiply by e^(-j*ω_if*t)
                digital_lo_I = np.cos(2 * np.pi * f_if * t)
                digital_lo_Q = -np.sin(2 * np.pi * f_if * t)  # for e^(-j*ω_if*t)

                # Complex multiplication: (I_if + j*Q_if) * (digital_lo_I + j*digital_lo_Q)
                # Real part (final I) = I_if * digital_lo_I - Q_if * digital_lo_Q
                # Imag part (final Q) = I_if * digital_lo_Q + Q_if * digital_lo_I
                I_baseband = I_if * digital_lo_I - Q_if * digital_lo_Q
                Q_baseband = I_if * digital_lo_Q + Q_if * digital_lo_I

            # Average the now-DC baseband signals to get the final point.
            I_val = np.mean(I_baseband[::sampling_factor])
            Q_val = np.mean(Q_baseband[::sampling_factor])

            return I_val, Q_val

        # Parallelize the loop for efficiency
        results = Parallel(n_jobs=-1)(
            delayed(_process_single_projection)()
            for _ in
            tqdm(range(self.num_iterations), postfix=signal_from_system.name, disable=self.disable_progress_bar)
        )

        I, Q = zip(*results)
        return I, Q

    def _plot_decision_regions(self, model, scaler, X_data, Y_data, title_suffix=""):
        plt.figure(figsize=(6, 8))

        # Define plot limits based on the provided X_data
        x_min, x_max = X_data[:, 0].min(), X_data[:, 0].max()
        y_min, y_max = X_data[:, 1].min(), X_data[:, 1].max()

        hshift = 0.5 * (x_max - x_min)
        x_min, x_max = x_min - hshift, x_max + hshift
        vshift = 0.5 * (y_max - y_min)
        y_min, y_max = y_min - vshift, y_max + vshift

        # Create a mesh (grid) of points for the decision boundary
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100),
                             )

        grid_points = np.c_[xx.ravel(), yy.ravel()]

        # Predict the class for each point on the grid using the provided model
        grid_predictions = model.predict(scaler.transform(grid_points)).reshape(xx.shape)

        # Plot the colored decision regions
        plt.imshow(grid_predictions,
                   aspect='auto',
                   alpha=0.2,
                   extent=(x_min, x_max, y_min, y_max),
                   origin='lower',
                   cmap=ListedColormap(['C0', 'C1']),
                   zorder=-3,
                   )

        # Plot the actual data points, colored by their state (Y_data)
        plt.scatter(X_data[Y_data == 0, 0], X_data[Y_data == 0, 1],
                    label=r"$|0\rangle$", c='C0', alpha=0.2, zorder=-1)
        plt.scatter(X_data[Y_data == 1, 0], X_data[Y_data == 1, 1],
                    label=r"$|1\rangle$", c='C1', alpha=0.2, zorder=-1)

        plt.xlabel("$I$ (a.u.)")
        plt.ylabel("$Q$ (a.u.)")
        plt.legend()
        plt.gca().set_aspect('equal', adjustable='box')
        plt.tight_layout()
        if self.path_for_images is not None:
            plt.savefig(os.path.join(self.path_for_images, "fidelity_simulation.pdf"), bbox_inches='tight')
            plt.savefig(os.path.join(self.path_for_images, "fidelity_simulation.png"), bbox_inches='tight')
        plt.title(f"IQ Projection Plot with Decision Regions {title_suffix}")
        plt.show()

    def _calculate_fidelity(self, I_state_0, Q_state_0, I_state_1, Q_state_1) -> float:

        # Combine I and Q lists
        X_state_0 = np.column_stack((I_state_0, Q_state_0))
        X_state_1 = np.column_stack((I_state_1, Q_state_1))

        # Create labels (Y) for each state
        Y_state_0 = np.zeros(len(I_state_0), dtype=int)
        Y_state_1 = np.ones(len(I_state_1), dtype=int)

        # Store combined features (X) and true labels (Y) as instance attributes
        X = np.vstack((X_state_0, X_state_1))
        Y = np.hstack((Y_state_0, Y_state_1))

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)  # Scale the full dataset

        # Split the data into 80% training and 20% testing sets
        X_train, X_test, Y_train, Y_test = train_test_split(X_scaled,
                                                            Y,
                                                            test_size=0.2,
                                                            random_state=42
                                                            )

        # Initialize and train the model
        model_for_evaluation = LinearDiscriminantAnalysis()
        model_for_evaluation.fit(X_train, Y_train)

        Y_pred = model_for_evaluation.predict(X_scaled)

        # Calculate the accuracy
        accuracy = accuracy_score(Y, Y_pred)

        # Plot the results if requested, using the model trained on X_train
        if self.plot_result:
            self._plot_decision_regions(model_for_evaluation, scaler, X, Y)

        return accuracy
