from typing import Union

import numpy as np
import skrf as rf
from joblib import Parallel, delayed
from matplotlib import pyplot as plt
from matplotlib.colors import ListedColormap
from scipy.signal import butter, filtfilt
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from skrf import Network
from tqdm import tqdm
from fidelity_analysis.pulse import Pulse, TransitedPulse, ReflectedPulse, ReadoutPulse

"""
Fidelity simulation based on the paper

Wong, Hiu Yung, Prabjot Dhillon, Kristin M. Beck, and Yaniv J. Rosen. 2023. 
“A Simulation Methodology for Superconducting Qubit Readout Fidelity.” 
Solid-State Electronics 201 (March):108582. https://doi.org/10.1016/j.sse.2022.108582.
"""


class FidelitySimulation:
    def __init__(
            self,
            readout_pulse: ReadoutPulse,
            s_parameters_file_state_0: Union[str, Network],
            s_parameters_file_state_1: Union[str, Network],
            IQ_projection_frequency: float,
            # readout_type can be "transition" or "reflection"
            readout_type: str = "transition",
            num_iterations: int = 50,
            noise_parameters: dict = None,
            # only needed if IQ_projection_frequency not the same as carrier_frequency of the readout pulse
            readout_dt: float = None,
            plot_pulses: bool = False,
            plot_result: bool = False,
            disable_progress_bar: bool = False,
    ):
        assert IQ_projection_frequency != readout_pulse.carrier_frequency

        self.s_parameters_file_state_0 = s_parameters_file_state_0
        self.s_parameters_file_state_1 = s_parameters_file_state_1
        self.readout_pulse = readout_pulse
        self.readout_type = readout_type
        self.IQ_projection_frequency = IQ_projection_frequency
        self.num_iterations = num_iterations
        self.readout_dt = readout_dt
        self.plot_pulses = plot_pulses
        self.plot_result = plot_result
        self.disable_progress_bar = disable_progress_bar

        # Noise parameters based on the paper
        self.amplifier_gains_db = {
            "TWPA": 20.0,
            "HEMT": 40.0,
            "RoomTemp": 40.0,
        }

        # Noise parameters based on the paper
        if noise_parameters is None:
            noise_parameters = {
                # This noise is generated by the first amplifier (TWPA)
                "quantum_noise": {
                    "type": "quantum",
                    "T_ns": 0.5,  # K
                    "bandwidth": 1 / self.readout_pulse.pulse_duration,
                    "stage": "TWPA"  # First stage
                },
                # This noise is from the HEMT, which is after the TWPA
                "thermal_noise_hemt": {
                    "type": "thermal",
                    "T_eff": 54,  # K
                    "bandwidth": 6e9,  # Hz
                    "resistance": 50.0,
                    "stage": "HEMT"  # Second stage
                },
                # This noise is from the room temp amp, after TWPA and HEMT
                "thermal_noise_room_temp": {
                    "type": "thermal",
                    "T_eff": 1.5,  # K (This value from the paper is unusually low for a 300K amp, but we follow it)
                    "bandwidth": 6e9,  # Hz
                    "resistance": 50.0,
                    "stage": "RoomTemp"  # Third stage
                }
            }
        self.noise_parameters = noise_parameters
        self.noise_parameters = noise_parameters

    def run(self) -> float:
        if type(self.s_parameters_file_state_0) is str:
            ntw_state_0 = rf.Network(self.s_parameters_file_state_0)
        else:
            ntw_state_0 = self.s_parameters_file_state_0
        if type(self.s_parameters_file_state_1) is str:
            ntw_state_1 = rf.Network(self.s_parameters_file_state_1)
        else:
            ntw_state_1 = self.s_parameters_file_state_1

        if self.readout_type == "transition":
            signal_state_0 = TransitedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_0,
                                            name=r"Transited Pulser $|0\rangle$")
            signal_state_1 = TransitedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_1,
                                            name=r"Transited Pulse $|1\rangle$")
        elif self.readout_type == "reflection":
            signal_state_0 = ReflectedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_0,
                                            name=r"Reflected Pulse $|0\rangle$")
            signal_state_1 = ReflectedPulse(original_pulse=self.readout_pulse, ntw=ntw_state_1,
                                            name=r"Reflected Pulse $|1\rangle$")
        else:
            raise NotImplementedError

        I_state_0, Q_state_0 = self._IQ_projection_demodulation(signal_from_system=signal_state_0)
        I_state_1, Q_state_1 = self._IQ_projection_demodulation(signal_from_system=signal_state_1)

        fidelity = self._calculate_fidelity(I_state_0, Q_state_0, I_state_1, Q_state_1)

        return fidelity

    # Noise independent of signal power, handling amplifier cascade and correct noise types
    def _create_noise(self, signal_from_system: Pulse) -> np.ndarray:
        k = 1.3806e-23  # Boltzmann constant (J/K)
        signal_length = len(signal_from_system.t_signal)
        total_noise_voltage = np.zeros(signal_length)

        dt = signal_from_system.t_signal_times[1] - signal_from_system.t_signal_times[0]
        sample_rate = 1 / dt

        stage_order = ["TWPA", "HEMT", "RoomTemp"]
        preceding_voltage_gain = 1.0

        for stage_name in stage_order:
            noise_params = None
            for name, params in self.noise_parameters.items():
                if params.get("stage") == stage_name:
                    noise_params = params
                    break

            if noise_params is None:
                continue

            noise_type = noise_params["type"]
            R = noise_params.get("resistance", 50.0)
            bandwidth = noise_params.get("bandwidth")

            if noise_type == "quantum":
                voltage_spectral_density = np.sqrt(k * noise_params["T_ns"] * R)
            elif noise_type == "thermal":
                voltage_spectral_density = np.sqrt(4 * k * noise_params["T_eff"] * R)
            else:
                raise ValueError(f"Unknown noise type: {noise_type}")

            sigma_full_bw = voltage_spectral_density * np.sqrt(1 / (2 * dt))
            unscaled_noise = np.random.normal(0, sigma_full_bw, size=signal_length)

            # The quantum noise is treated as white noise. Its effective bandwidth is
            # determined by the integration time in the demodulation, not by pre-filtering.
            # Thermal amplifier noise IS physically band-limited, so we filter it.
            if noise_type != "quantum":
                nyquist_freq = 0.5 * sample_rate
                if bandwidth is not None and bandwidth < nyquist_freq:
                    b, a = butter(1, bandwidth, btype='lowpass', fs=sample_rate)
                    unscaled_noise = filtfilt(b, a, unscaled_noise)

            referred_noise = unscaled_noise / preceding_voltage_gain
            total_noise_voltage += referred_noise

            stage_power_gain_db = self.amplifier_gains_db.get(stage_name, 0)
            stage_power_gain_linear = 10 ** (stage_power_gain_db / 10.0)
            stage_voltage_gain = np.sqrt(stage_power_gain_linear)
            preceding_voltage_gain *= stage_voltage_gain

        return total_noise_voltage

    def _IQ_projection_demodulation(self, signal_from_system: Pulse):
        if self.plot_pulses:
            signal_from_system.plot_pulse()

        dt = signal_from_system.t_signal_times[1] - signal_from_system.t_signal_times[0]
        sample_rate = 1 / dt
        t = signal_from_system.t_signal_times

        # --- Define Frequencies ---
        f_ro = self.readout_pulse.carrier_frequency  # Readout frequency (from cryostat)
        f_lo = self.IQ_projection_frequency  # Local Oscillator frequency
        f_if = f_ro - f_lo  # Intermediate Frequency (IF)

        # --- Stage 1: Analog Down-conversion (to IF) ---
        # This stage simulates mixing the signal with the LO and low-pass filtering.
        # The filter must pass f_if but reject the sum frequency (f_ro + f_lo).
        # A good cutoff is a few times f_if. Let's use 2*f_if as a safe margin.
        cutoff_analog = np.abs(f_if * 2)
        # noinspection PyTupleAssignmentBalance
        b_analog, a_analog = butter(1, cutoff_analog, btype="lowpass", fs=sample_rate)

        if self.readout_dt:
            sampling_factor = int(self.readout_dt / dt)
            if sampling_factor < 1: sampling_factor = 1
        else:
            sampling_factor = 1

        def _process_single_projection():
            # Get the noisy signal from the system
            noise = self._create_noise(signal_from_system=signal_from_system)
            s = signal_from_system.t_signal.real + noise

            # === STAGE 1: SIMULATE ANALOG MIXING TO IF ===
            # Local Oscillator (LO) at f_lo
            lo_I = np.cos(2 * np.pi * f_lo * t)
            lo_Q = -np.sin(2 * np.pi * f_lo * t)

            # Mix down
            mixed_analog_I = s * lo_I
            mixed_analog_Q = s * lo_Q

            # Low-pass filter to isolate the IF signal
            I_if = filtfilt(b_analog, a_analog, mixed_analog_I)
            Q_if = filtfilt(b_analog, a_analog, mixed_analog_Q)

            # === STAGE 2: SIMULATE DIGITAL MIXING FROM IF TO DC ===
            # Create a digital complex oscillator at f_if to mix down to 0 Hz (DC).
            # We need to create z_if = I_if + j*Q_if and multiply by e^(-j*ω_if*t)
            digital_lo_I = np.cos(2 * np.pi * f_if * t)
            digital_lo_Q = -np.sin(2 * np.pi * f_if * t)  # for e^(-j*ω_if*t)

            # Complex multiplication: (I_if + j*Q_if) * (digital_lo_I + j*digital_lo_Q)
            # Real part (final I) = I_if * digital_lo_I - Q_if * digital_lo_Q
            # Imag part (final Q) = I_if * digital_lo_Q + Q_if * digital_lo_I
            I_baseband = I_if * digital_lo_I - Q_if * digital_lo_Q
            Q_baseband = I_if * digital_lo_Q + Q_if * digital_lo_I

            # === STAGE 3: INTEGRATION ===
            # Average the now-DC baseband signals to get the final point.
            # The factor of 4 accounts for the 0.5 amplitude loss at each of the two mixing stages.
            I_val = 4 * np.mean(I_baseband[::sampling_factor])
            Q_val = 4 * np.mean(Q_baseband[::sampling_factor])

            return I_val, Q_val

        # Parallelize the loop
        results = Parallel(n_jobs=-1)(
            delayed(_process_single_projection)()
            for _ in
            tqdm(range(self.num_iterations), postfix=signal_from_system.name, disable=self.disable_progress_bar)
        )

        # Unpack the results
        I, Q = zip(*results)
        return I, Q

    @staticmethod
    def _plot_decision_regions(model, scaler, X_data, Y_data, title_suffix=""):
        plt.figure(figsize=(6, 8))

        # Define plot limits based on the provided X_data
        x_min, x_max = X_data[:, 0].min(), X_data[:, 0].max()
        y_min, y_max = X_data[:, 1].min(), X_data[:, 1].max()

        hshift = 0.5 * (x_max - x_min)
        x_min, x_max = x_min - hshift, x_max + hshift
        vshift = 0.5 * (y_max - y_min)
        y_min, y_max = y_min - vshift, y_max + vshift

        # Create a mesh (grid) of points for the decision boundary
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100),
                             )

        grid_points = np.c_[xx.ravel(), yy.ravel()]

        # Predict the class for each point on the grid using the provided model
        grid_predictions = model.predict(scaler.transform(grid_points)).reshape(xx.shape)

        # Plot the colored decision regions
        plt.imshow(grid_predictions,
                   aspect='auto',
                   alpha=0.2,
                   extent=(x_min, x_max, y_min, y_max),
                   origin='lower',
                   cmap=ListedColormap(['C0', 'C1']),
                   zorder=-3,
                   )

        # Plot the actual data points, colored by their state (Y_data)
        plt.scatter(X_data[Y_data == 0, 0], X_data[Y_data == 0, 1],
                    label=r"$|0\rangle$", c='C0', alpha=0.2, zorder=-1)
        plt.scatter(X_data[Y_data == 1, 0], X_data[Y_data == 1, 1],
                    label=r"$|1\rangle$", c='C1', alpha=0.2, zorder=-1)

        plt.xlabel("$I$ (a.u.)")
        plt.ylabel("$Q$ (a.u.)")
        plt.legend()
        plt.gca().set_aspect('equal', adjustable='box')
        plt.tight_layout()
        plt.savefig("fidelity_simulation.pdf", bbox_inches='tight')
        plt.savefig("fidelity_simulation.png", bbox_inches='tight')
        plt.title(f"IQ Projection Plot with Decision Regions {title_suffix}")
        plt.show()

    def _calculate_fidelity(self, I_state_0, Q_state_0, I_state_1, Q_state_1) -> float:

        # Combine I and Q lists
        X_state_0 = np.column_stack((I_state_0, Q_state_0))
        X_state_1 = np.column_stack((I_state_1, Q_state_1))

        # Create labels (Y) for each state
        Y_state_0 = np.zeros(len(I_state_0), dtype=int)
        Y_state_1 = np.ones(len(I_state_1), dtype=int)

        # Store combined features (X) and true labels (Y) as instance attributes
        X = np.vstack((X_state_0, X_state_1))
        Y = np.hstack((Y_state_0, Y_state_1))

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)  # Scale the full dataset

        # Split the data into 80% training and 20% testing sets
        X_train, X_test, Y_train, Y_test = train_test_split(X_scaled,
                                                            Y,
                                                            test_size=0.2,
                                                            random_state=42
                                                            )

        # Initialize and train a Logistic Regression model on the training data
        model_for_evaluation = LinearDiscriminantAnalysis()
        model_for_evaluation.fit(X_train, Y_train)

        Y_pred = model_for_evaluation.predict(X_scaled)

        # Calculate the accuracy
        accuracy = accuracy_score(Y, Y_pred)

        # Plot the results if requested, using the model trained on X_train
        if self.plot_result:
            self._plot_decision_regions(model_for_evaluation, scaler, X, Y)

        return accuracy
